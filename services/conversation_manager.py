"""
ìˆ˜ì •ëœ Conversation Manager - ì˜¬ë°”ë¥¸ LangGraph ë…¸ë“œ ì‹¤í–‰
"""

import asyncio
import logging
import threading
import time
import queue
from datetime import datetime
from typing import Optional, Dict, Any, Callable, Protocol
from enum import Enum

from services.stream_stt import RTZROpenAPIClient
from core.graph import VoiceFriendlyPhishingGraph
from services.tts_service import tts_service
from services.audio_manager import audio_manager
from config.settings import settings

logger = logging.getLogger(__name__)

class ConversationState(Enum):
    """ëŒ€í™” ìƒíƒœ"""
    IDLE = "idle"
    LISTENING = "listening"
    PROCESSING = "processing"
    SPEAKING = "speaking"
    ERROR = "error"

class FixedVoiceFriendlyConversationManager:
    """
    ìˆ˜ì •ëœ ìŒì„± ëŒ€í™” ë§¤ë‹ˆì € - ì˜¬ë°”ë¥¸ LangGraph ë…¸ë“œ ì‹¤í–‰
    """
    
    def __init__(self, client_id: str, client_secret: str):
        self.client_id = client_id
        self.client_secret = client_secret
        
        # ğŸ”¥ í•µì‹¬: AI ë‘ë‡Œë¥¼ ì˜¬ë°”ë¥´ê²Œ ì‚¬ìš©
        self.ai_brain = VoiceFriendlyPhishingGraph(debug=settings.DEBUG)
        self.tts_service = tts_service
        self.audio_manager = audio_manager
        
        # STT ì»´í¬ë„ŒíŠ¸
        self.stt_client = None
        self.stt_queue = queue.Queue(maxsize=5)
        self.stt_thread: Optional[threading.Thread] = None

        # ìƒíƒœ ê´€ë¦¬
        self.state = ConversationState.IDLE
        self.is_running = False
        self.is_processing = False
        self.initialization_complete = False
        self.error_count = 0

        # ğŸ”¥ í•µì‹¬: LangGraph ìƒíƒœ ê´€ë¦¬
        self.current_graph_state = None
        self.session_id = None

        # ì½œë°± ê´€ë¦¬
        self.callbacks: Dict[str, Optional[Callable]] = {
            'on_user_speech': None,
            'on_ai_response': None,
            'on_state_change': None,
            'on_error': None
        }
        
        # ì„±ëŠ¥ í†µê³„
        self.stats = {
            'conversation_start_time': None,
            'initialization_attempts': 0,
            'total_pipeline_runs': 0,
            'avg_pipeline_time': 0.0,
            'stt_errors': 0,
            'ai_errors': 0,
            'tts_errors': 0,
        }
        
        logger.info("âœ… ìˆ˜ì •ëœ ëŒ€í™” ë§¤ë‹ˆì € ì´ˆê¸°í™” ì™„ë£Œ")

    async def initialize(self) -> bool:
        """ê°œì„ ëœ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.stats['initialization_attempts'] += 1
        logger.info(f"ğŸ¬ ìŒì„± ëŒ€í™” íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (ì‹œë„ {self.stats['initialization_attempts']})...")
        
        try:
            # 1. ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™”
            logger.info("ğŸ”Š ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì¤‘...")
            if not self.audio_manager.initialize_output():
                logger.error("âŒ ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨")
                return False
            logger.info("âœ… ì˜¤ë””ì˜¤ íŒŒì´í”„ë¼ì¸ ì¤€ë¹„")
            
            # 2. STT í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            logger.info("ğŸ¤ STT í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì¤‘...")
            self.stt_client = RTZROpenAPIClient(self.client_id, self.client_secret)
            logger.info("âœ… STT í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„")
            
            # ğŸ”¥ í•µì‹¬ ìˆ˜ì •: LangGraph ì„¸ì…˜ ì‹œì‘
            logger.info("ğŸ§  LangGraph ì„¸ì…˜ ì‹œì‘ ì¤‘...")
            self.session_id = f"voice_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            self.current_graph_state = await self.ai_brain.start_conversation(self.session_id)
            logger.info(f"âœ… LangGraph ì„¸ì…˜ ì‹œì‘: {self.session_id}")
            
            # 4. ì´ˆê¸° ì¸ì‚¬ (LangGraphì—ì„œ ìƒì„±ëœ ë©”ì‹œì§€ ì‚¬ìš©)
            await self._deliver_langgraph_greeting()
            
            self.initialization_complete = True
            self.stats['conversation_start_time'] = datetime.now()
            self._set_state(ConversationState.LISTENING)
            
            logger.info("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ!")
            return True
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    async def _deliver_langgraph_greeting(self):
        """LangGraphì—ì„œ ìƒì„±ëœ ì´ˆê¸° ì¸ì‚¬ ì „ë‹¬"""
        try:
            # LangGraph ìƒíƒœì—ì„œ ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
            if self.current_graph_state and self.current_graph_state.get("messages"):
                messages = self.current_graph_state["messages"]
                for msg in reversed(messages):
                    if msg.get("role") == "assistant":
                        greeting_text = msg.get("content", "")
                        if greeting_text:
                            await self._safe_tts_delivery(greeting_text)
                            logger.info("âœ… LangGraph ì´ˆê¸° ì¸ì‚¬ ì „ë‹¬ ì™„ë£Œ")
                            return
            
            # í´ë°±: ê¸°ë³¸ ì¸ì‚¬
            fallback_greeting = "ì•ˆë…•í•˜ì„¸ìš”. ë³´ì´ìŠ¤í”¼ì‹± ìƒë‹´ì„¼í„°ì…ë‹ˆë‹¤. 1ë²ˆ ë˜ëŠ” 2ë²ˆì„ ì„ íƒí•´ì£¼ì„¸ìš”."
            await self._safe_tts_delivery(fallback_greeting)
            logger.warning("âš ï¸ LangGraph ì¸ì‚¬ ì—†ìŒ - í´ë°± ì‚¬ìš©")
            
        except Exception as e:
            logger.error(f"ì´ˆê¸° ì¸ì‚¬ ì „ë‹¬ ì‹¤íŒ¨: {e}")

    async def start_conversation(self):
        """ëŒ€í™” ì‹œì‘"""
        if not await self.initialize():
            logger.error("âŒ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹¤íŒ¨")
            return
        
        self.is_running = True
        logger.info("ğŸ™ï¸ ìŒì„± ëŒ€í™” ì‹œì‘")
        
        try:
            # STT ì…ë ¥ ì‹œì‘
            self._start_stt_input_safe()
            
            # ë©”ì¸ ë£¨í”„
            await self._safe_main_loop()
            
        except KeyboardInterrupt:
            logger.info("ì‚¬ìš©ì ì¢…ë£Œ")
        except Exception as e:
            logger.error(f"ëŒ€í™” ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        finally:
            await self.cleanup()

    def _start_stt_input_safe(self):
        """ì•ˆì „í•œ STT ì…ë ¥ ì‹œì‘"""
        def stt_worker():
            retry_count = 0
            max_retries = 3
            
            while self.is_running and retry_count < max_retries:
                try:
                    logger.info(f"ğŸ¤ STT ìŠ¤íŠ¸ë¦¼ ì‹œì‘ ì‹œë„ {retry_count + 1}/{max_retries}")
                    
                    if self.stt_client:
                        self.stt_client.reset_stream()
                    
                    def transcript_handler(start_time, transcript, is_final=False):
                        if is_final and transcript.alternatives:
                            text = transcript.alternatives[0].text.strip()
                            if text and len(text) > 1:
                                self._safe_add_to_queue(text)
                                logger.debug(f"ğŸ¤ STT ì…ë ¥: {text}")
                    
                    self.stt_client.print_transcript = transcript_handler
                    self.stt_client.transcribe_streaming_grpc()
                    
                    logger.info("âœ… STT ìŠ¤íŠ¸ë¦¼ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë¨")
                    break
                    
                except Exception as e:
                    retry_count += 1
                    self.stats['stt_errors'] += 1
                    logger.error(f"STT ìŠ¤íŠ¸ë¦¼ ì˜¤ë¥˜ (ì‹œë„ {retry_count}): {e}")
                    
                    if retry_count < max_retries:
                        logger.info(f"ğŸ”„ {retry_count + 1}ì´ˆ í›„ STT ì¬ì‹œë„...")
                        time.sleep(retry_count + 1)
                    else:
                        logger.error("âŒ STT ìŠ¤íŠ¸ë¦¼ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                        break
        
        self.stt_thread = threading.Thread(
            target=stt_worker, 
            daemon=True, 
            name="STT-Worker"
        )
        self.stt_thread.start()
        logger.info("ğŸ¤ STT ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")

    def _safe_add_to_queue(self, text: str):
        """ì•ˆì „í•œ í ì¶”ê°€"""
        try:
            if not self.stt_queue.full():
                self.stt_queue.put_nowait(text)
            else:
                try:
                    self.stt_queue.get_nowait()
                    self.stt_queue.put_nowait(text)
                except queue.Empty:
                    pass
        except Exception as e:
            logger.warning(f"í ì¶”ê°€ ì˜¤ë¥˜: {e}")

    async def _safe_main_loop(self):
        """ì•ˆì „í•œ ë©”ì¸ ë£¨í”„"""
        consecutive_errors = 0
        max_consecutive_errors = 5
        
        logger.info("ğŸ”„ ë©”ì¸ ì²˜ë¦¬ ë£¨í”„ ì‹œì‘")
        
        while self.is_running:
            try:
                # STT ì…ë ¥ í™•ì¸
                user_input = self._get_stt_input()
                
                if user_input and not self.is_processing:
                    logger.info(f"ğŸ‘¤ ì‚¬ìš©ì ì…ë ¥ ê°ì§€: {user_input}")
                    # ğŸ”¥ í•µì‹¬: LangGraph ë…¸ë“œ ì‹œìŠ¤í…œ ì‚¬ìš©
                    await self._process_through_langgraph(user_input)
                
                # ëŒ€í™” ì™„ë£Œ í™•ì¸
                if self._check_conversation_complete():
                    logger.info("âœ… ëŒ€í™” ì™„ë£Œ ì‹ í˜¸ ê°ì§€")
                    break
                
                await asyncio.sleep(0.1)
                consecutive_errors = 0
                        
            except Exception as e:
                consecutive_errors += 1
                logger.error(f"ë©”ì¸ ë£¨í”„ ì˜¤ë¥˜ ({consecutive_errors}/{max_consecutive_errors}): {e}")
                
                if consecutive_errors >= max_consecutive_errors:
                    logger.error("âŒ ë©”ì¸ ë£¨í”„ ì—°ì† ì˜¤ë¥˜ í•œê³„ ì´ˆê³¼")
                    break
                
                await asyncio.sleep(min(consecutive_errors * 0.5, 3.0))

    def _get_stt_input(self) -> Optional[str]:
        """STT íì—ì„œ ì…ë ¥ ê°€ì ¸ì˜¤ê¸°"""
        try:
            return self.stt_queue.get_nowait()
        except queue.Empty:
            return None

    async def _process_through_langgraph(self, user_input: str):
        """ğŸ”¥ í•µì‹¬: LangGraph ë…¸ë“œ ì‹œìŠ¤í…œì„ í†µí•œ ì²˜ë¦¬"""
        self.is_processing = True
        self._set_state(ConversationState.PROCESSING)
        
        start_time = time.time()
        
        try:
            # ì‚¬ìš©ì ì…ë ¥ ì½œë°±
            if self.callbacks['on_user_speech']:
                try:
                    self.callbacks['on_user_speech'](user_input)
                except Exception as e:
                    logger.warning(f"ì‚¬ìš©ì ì…ë ¥ ì½œë°± ì˜¤ë¥˜: {e}")
            
            # ğŸ”¥ í•µì‹¬: LangGraphì˜ continue_conversation ì‚¬ìš©
            logger.info("ğŸ§  LangGraph ë…¸ë“œ ì‹œìŠ¤í…œìœ¼ë¡œ ì²˜ë¦¬ ì¤‘...")
            
            self.current_graph_state = await self.ai_brain.continue_conversation(
                self.current_graph_state, 
                user_input
            )
            
            # ğŸ”¥ í•µì‹¬: LangGraph ìƒíƒœì—ì„œ AI ì‘ë‹µ ì¶”ì¶œ
            ai_response = self._extract_latest_ai_response()
            
            if ai_response:
                logger.info(f"ğŸ¤– LangGraph AI ì‘ë‹µ: {ai_response}")
                
                # AI ì‘ë‹µ ì½œë°±
                if self.callbacks['on_ai_response']:
                    try:
                        self.callbacks['on_ai_response'](ai_response)
                    except Exception as e:
                        logger.warning(f"AI ì‘ë‹µ ì½œë°± ì˜¤ë¥˜: {e}")
                
                # TTS ì²˜ë¦¬
                await self._safe_tts_delivery(ai_response)
            else:
                logger.warning("LangGraphì—ì„œ AI ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í•¨")
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            processing_time = time.time() - start_time
            self._update_pipeline_stats(processing_time)
            
        except Exception as e:
            logger.error(f"LangGraph ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            await self._handle_processing_error(e)
        finally:
            self.is_processing = False
            self._set_state(ConversationState.LISTENING)

    def _extract_latest_ai_response(self) -> Optional[str]:
        """LangGraph ìƒíƒœì—ì„œ ìµœì‹  AI ì‘ë‹µ ì¶”ì¶œ"""
        try:
            if not self.current_graph_state or not self.current_graph_state.get("messages"):
                return None
            
            messages = self.current_graph_state["messages"]
            
            # ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ ì°¾ê¸°
            for msg in reversed(messages):
                if msg.get("role") == "assistant":
                    content = msg.get("content", "").strip()
                    if content:
                        return content
            
            return None
            
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None

    async def _safe_tts_delivery(self, response_text: str):
        """ì•ˆì „í•œ TTS ì „ë‹¬"""
        self._set_state(ConversationState.SPEAKING)
        
        try:
            if not self.tts_service.is_enabled:
                print(f"ğŸ¤– {response_text}")
                return
            
            try:
                audio_stream = self.tts_service.text_to_speech_stream(response_text)
                await self.audio_manager.play_audio_stream(audio_stream)
                
            except Exception as tts_error:
                logger.error(f"TTS ì²˜ë¦¬ ì˜¤ë¥˜: {tts_error}")
                print(f"ğŸ¤– {response_text}")
                self.stats['tts_errors'] += 1
                
        except Exception as e:
            logger.error(f"TTS ì „ë‹¬ ì˜¤ë¥˜: {e}")
            print(f"ğŸ¤– {response_text}")

    def _check_conversation_complete(self) -> bool:
        """ëŒ€í™” ì™„ë£Œ ì—¬ë¶€ í™•ì¸"""
        try:
            # ğŸ”¥ í•µì‹¬: LangGraph AI ë‘ë‡Œì˜ ì™„ë£Œ ì—¬ë¶€ í™•ì¸
            return self.ai_brain.is_conversation_complete()
        except Exception as e:
            logger.debug(f"ëŒ€í™” ì™„ë£Œ í™•ì¸ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
            return False

    async def _handle_processing_error(self, error: Exception):
        """ì²˜ë¦¬ ì˜¤ë¥˜ í•¸ë“¤ë§"""
        self.error_count += 1
        
        if self.callbacks['on_error']:
            try:
                self.callbacks['on_error'](error)
            except Exception:
                pass
        
        fallback_response = "ì¼ì‹œì  ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. 132ë²ˆìœ¼ë¡œ ì—°ë½ì£¼ì„¸ìš”."
        await self._safe_tts_delivery(fallback_response)

    def _update_pipeline_stats(self, processing_time: float):
        """íŒŒì´í”„ë¼ì¸ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.stats['total_pipeline_runs'] += 1
        
        current_avg = self.stats['avg_pipeline_time']
        total_runs = self.stats['total_pipeline_runs']
        self.stats['avg_pipeline_time'] = (
            (current_avg * (total_runs - 1) + processing_time) / total_runs
        )

    def _set_state(self, new_state: ConversationState):
        """ìƒíƒœ ë³€ê²½"""
        if self.state != new_state:
            old_state = self.state
            self.state = new_state
            
            if self.callbacks['on_state_change']:
                try:
                    self.callbacks['on_state_change'](old_state, new_state)
                except Exception as e:
                    logger.warning(f"ìƒíƒœ ë³€ê²½ ì½œë°± ì˜¤ë¥˜: {e}")

    def set_callbacks(self, 
                     on_user_speech: Optional[Callable] = None,
                     on_ai_response: Optional[Callable] = None, 
                     on_state_change: Optional[Callable] = None,
                     on_error: Optional[Callable] = None):
        """ì½œë°± ì„¤ì •"""
        if on_user_speech:
            self.callbacks['on_user_speech'] = on_user_speech
        if on_ai_response:
            self.callbacks['on_ai_response'] = on_ai_response
        if on_state_change:
            self.callbacks['on_state_change'] = on_state_change
        if on_error:
            self.callbacks['on_error'] = on_error

    def get_conversation_status(self) -> Dict[str, Any]:
        """ëŒ€í™” ìƒíƒœ ì¡°íšŒ"""
        elapsed_time = 0
        if self.stats['conversation_start_time']:
            elapsed_time = (datetime.now() - self.stats['conversation_start_time']).total_seconds()
        
        return {
            "state": self.state.value,
            "is_running": self.is_running,
            "is_processing": self.is_processing,
            "initialization_complete": self.initialization_complete,
            "elapsed_time": elapsed_time,
            "total_turns": self.stats['total_pipeline_runs'],
            "avg_response_time": self.stats['avg_pipeline_time'],
            "error_count": self.error_count,
            "stt_errors": self.stats['stt_errors'],
            "ai_errors": self.stats['ai_errors'],
            "tts_errors": self.stats['tts_errors'],
            "current_graph_state": self.current_graph_state.get("current_step") if self.current_graph_state else None,
            "session_id": self.session_id
        }

    def get_audio_status(self) -> dict:
        """ì˜¤ë””ì˜¤ ìƒíƒœ"""
        try:
            return self.audio_manager.get_performance_stats()
        except Exception as e:
            logger.warning(f"ì˜¤ë””ì˜¤ ìƒíƒœ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {'error': str(e), 'is_available': False}

    async def cleanup(self):
        """íŒŒì´í”„ë¼ì¸ ì •ë¦¬"""
        logger.info("ğŸ§¹ íŒŒì´í”„ë¼ì¸ ì •ë¦¬ ì¤‘...")
        
        try:
            self.is_running = False
            self.is_processing = False
            
            # STT ìŠ¤ë ˆë“œ ì •ë¦¬
            if self.stt_thread and self.stt_thread.is_alive():
                logger.info("ğŸ¤ STT ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°...")
                self.stt_thread.join(timeout=3)
            
            # STT í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
            if self.stt_client and hasattr(self.stt_client, 'stream'):
                try:
                    self.stt_client.stream.terminate()
                except Exception as e:
                    logger.debug(f"STT ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
            
            # í ì •ë¦¬
            while not self.stt_queue.empty():
                try:
                    self.stt_queue.get_nowait()
                except queue.Empty:
                    break
            
            # ì˜¤ë””ì˜¤ ë§¤ë‹ˆì € ì •ë¦¬
            try:
                self.audio_manager.cleanup()
            except Exception as e:
                logger.warning(f"ì˜¤ë””ì˜¤ ì •ë¦¬ ì˜¤ë¥˜: {e}")
            
            # ğŸ”¥ í•µì‹¬: LangGraph AI ì •ë¦¬
            try:
                if self.ai_brain:
                    await self.ai_brain.cleanup()
            except Exception as e:
                logger.warning(f"LangGraph ì •ë¦¬ ì˜¤ë¥˜: {e}")
            
            # ìµœì¢… í†µê³„
            self._print_final_stats()
            
            logger.info("âœ… íŒŒì´í”„ë¼ì¸ ì •ë¦¬ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ì •ë¦¬ ì˜¤ë¥˜: {e}")

    def _print_final_stats(self):
        """ìµœì¢… í†µê³„ ì¶œë ¥"""
        if self.stats['conversation_start_time']:
            total_time = (datetime.now() - self.stats['conversation_start_time']).total_seconds()
            
            logger.info("ğŸ“Š ìµœì¢… íŒŒì´í”„ë¼ì¸ í†µê³„:")
            logger.info(f"   ì´ ì‹œê°„: {total_time:.1f}ì´ˆ")
            logger.info(f"   ì´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: {self.stats['total_pipeline_runs']}")
            logger.info(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {self.stats['avg_pipeline_time']:.3f}ì´ˆ")
            logger.info(f"   ì´ˆê¸°í™” ì‹œë„: {self.stats['initialization_attempts']}")
            logger.info(f"   STT ì˜¤ë¥˜: {self.stats['stt_errors']}")
            logger.info(f"   AI ì˜¤ë¥˜: {self.stats['ai_errors']}")
            logger.info(f"   TTS ì˜¤ë¥˜: {self.stats['tts_errors']}")


# í•˜ìœ„ í˜¸í™˜ì„±
VoiceFriendlyConversationManager = FixedVoiceFriendlyConversationManager
ConversationManager = FixedVoiceFriendlyConversationManager